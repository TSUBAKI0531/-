import json
import os
import pandas as pd
import freesasa
from rdkit import Chem
from Bio.PDB import MMCIFParser, NeighborSearch
import py3Dmol

class GlycoConjugateWorkflow:
    """
    ç³–é–æŠ±åˆãƒ¯ã‚¯ãƒãƒ³ã®AF3æº–å‚™ã€ä¸€æ‹¬è§£æã€ãŠã‚ˆã³ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’è¡Œã†çµ±åˆã‚¯ãƒ©ã‚¹
    """
    def __init__(self, job_name):
        self.job_name = job_name
        self.results_df = None

    # --- 1. æº–å‚™ãƒ•ã‚§ãƒ¼ã‚º: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç‰¹å®šã¨JSONä½œæˆ ---

    def _get_af3_atom_name(self, mol, target_idx):
        """RDKitã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’AF3å½¢å¼(ä¾‹: C12)ã«å¤‰æ›"""
        atom = mol.GetAtomWithIdx(target_idx)
        symbol = atom.GetSymbol()
        count = 0
        for i, a in enumerate(mol.GetAtoms()):
            if a.GetSymbol() == symbol:
                count += 1
            if i == target_idx:
                return f"{symbol}{count}"
        return None

    def find_terminal_atom(self, smiles, smarts_pattern):
        """SMARTSãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç”¨ã„ã¦çµåˆåŸå­ã‚’è‡ªå‹•ç‰¹å®š"""
        mol = Chem.MolFromSmiles(smiles)
        pattern = Chem.MolFromSmarts(smarts_pattern)
        matches = mol.GetSubstructMatches(pattern)
        if not matches:
            raise ValueError(f"ãƒ‘ã‚¿ãƒ¼ãƒ³ '{smarts_pattern}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        
        target_idx = matches[0][0] # ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æœ€åˆã®åŸå­ã‚’é¸æŠ
        return self._get_af3_atom_name(mol, target_idx)

    def prepare_af3_input(self, protein_seq, taca_linker_smiles, bond_res_idx, terminal_smarts, bond_atom_protein="NZ"):
        """AF3å®Ÿè¡Œç”¨ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ"""
        bond_atom_ligand = self.find_terminal_atom(taca_linker_smiles, terminal_smarts)
        
        data = {
            "name": self.job_name,
            "modelSeeds": [1],
            "sequences": [
                {"protein": {"id": "A", "sequence": protein_seq}},
                {"ligand": {"id": "B", "smiles": taca_linker_smiles}}
            ],
            "bondedAtomPairs": [
                {
                    "at1": {"resChainId": "A", "resIdx": bond_res_idx, "atomName": bond_atom_protein},
                    "at2": {"resChainId": "B", "resIdx": 1, "atomName": bond_atom_ligand}
                }
            ]
        }
        
        output_path = f"{self.job_name}.json"
        with open(output_path, "w") as f:
            json.dump(data, f, indent=4)
        print(f"âœ… AF3ç”¨JSONã‚’ä½œæˆå®Œäº†: {output_path} (çµåˆåŸå­: {bond_atom_ligand})")
        return output_path

    # --- 2. è§£æãƒ•ã‚§ãƒ¼ã‚º: SASAãŠã‚ˆã³ç›¸äº’ä½œç”¨è§£æ ---

    def analyze_interactions(self, cif_path, distance_cutoff=5.0):
        """æŒ‡å®šã•ã‚ŒãŸCIFãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ¥è§¦æ®‹åŸºã‚’ç‰¹å®š"""
        parser = MMCIFParser(QUIET=True)
        structure = parser.get_structure("model", cif_path)
        model = structure[0]
        
        protein_atoms = [a for a in model.get_atoms() if a.get_parent().get_resname() not in ["HOH"]]
        # ç³–é–(Ligand)ã¯AF3ã§ã¯é€šå¸¸ãƒ˜ãƒ†ãƒ­åŸå­ã¨ã—ã¦æ‰±ã‚ã‚Œã‚‹
        sugar_atoms = [a for a in model.get_atoms() if "H_" in a.get_parent().get_full_id()[3][0]]
        
        ns = NeighborSearch(protein_atoms)
        contact_residues = set()
        for s_atom in sugar_atoms:
            contacts = ns.search(s_atom.coord, distance_cutoff)
            for c_atom in contacts:
                res = c_atom.get_parent()
                contact_residues.add(f"{res.get_resname()}{res.id[1]}")
        return sorted(list(contact_residues))

    def _calculate_sasa(self, cif_path):
        """FreeSASAã‚’ç”¨ã„ã¦éœ²å‡ºé¢ç©ã‚’è¨ˆç®—"""
        structure = freesasa.Structure(cif_path)
        result = freesasa.calc(structure)
        
        # Chain Aã‚’ã‚¿ãƒ³ãƒ‘ã‚¯ã€ãã‚Œä»¥å¤–ã‚’ç³–é–ã¨å®šç¾©
        s_prot = freesasa.selectObjects(["prot, chain A"], structure, result)
        s_glyc = freesasa.selectObjects(["glyc, not chain A"], structure, result)
        
        return {
            "protein_sasa": s_prot["prot"],
            "glycan_sasa": s_glyc["glyc"]
        }

    def batch_analyze_models(self, num_models=5):
        """å…¨ãƒ¢ãƒ‡ãƒ«ã‚’ä¸€æ‹¬è§£æã—ã€æŠ—åŸæç¤ºã®è³ªã§ãƒ©ãƒ³ã‚­ãƒ³ã‚°"""
        analysis_data = []
        
        for i in range(num_models):
            file_path = f"{self.job_name}_model_{i}.cif"
            if not os.path.exists(file_path):
                continue
            
            # SASAè¨ˆç®—
            sasa = self._calculate_sasa(file_path)
            # æ¥è§¦æ®‹åŸº
            contacts = self.analyze_interactions(file_path)
            
            # ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°: (ç³–é–éœ²å‡ºé¢ç©) / (æ¥è§¦æ®‹åŸºæ•° + 1)
            # å€¤ãŒé«˜ã„ã»ã©ã€Œã‚¿ãƒ³ãƒ‘ã‚¯è³ªã«åŸ‹ã‚‚ã‚Œãšã€å¤–å´ã‚’å‘ã„ã¦ã„ã‚‹ã€ã¨è©•ä¾¡
            exposure_score = sasa["glycan_sasa"] / (len(contacts) + 1)
            
            analysis_data.append({
                "Model_Index": i,
                "Glycan_SASA": round(sasa["glycan_sasa"], 2),
                "Contact_Res_Count": len(contacts),
                "Exposure_Score": round(exposure_score, 2),
                "File": file_path
            })
        
        self.results_df = pd.DataFrame(analysis_data).sort_values(by="Exposure_Score", ascending=False)
        print("\nğŸ† ãƒ¢ãƒ‡ãƒ«è§£æãƒ©ãƒ³ã‚­ãƒ³ã‚° (Exposure_Scoreé †):")
        print(self.results_df.to_string(index=False))
        return self.results_df

    # --- 3. å¯è¦–åŒ–ãƒ•ã‚§ãƒ¼ã‚º ---

    def visualize_model(self, model_idx):
        """æŒ‡å®šã—ãŸãƒ¢ãƒ‡ãƒ«ç•ªå·ã®æ§‹é€ ã‚’è¡¨ç¤º"""
        file_path = f"{self.job_name}_model_{model_idx}.cif"
        if not os.path.exists(file_path):
            print("ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            return
            
        view = py3Dmol.view(width=800, height=600)
        with open(file_path, 'r') as f:
            view.addModel(f.read(), 'mcif')
        
        view.setStyle({'cartoon': {'color': 'spectrum'}}) # ã‚¿ãƒ³ãƒ‘ã‚¯ã¯ä¿¡é ¼åº¦
        view.setStyle({'hetflag': True}, {'stick': {'colorscheme': 'magentaCarbon'}}) # ç³–é–ã¯ãƒã‚¼ãƒ³ã‚¿
        view.zoomTo({'hetflag': True})
        print(f"Visualizing Model {model_idx}...")
        return view.show()

# --- å®Ÿéš›ã®é‹ç”¨ä¾‹ ---

# 1. åˆæœŸåŒ–
wf = GlycoConjugateWorkflow("TACA_Vaccine_Project")

# 2. AF3ã®æº–å‚™ (SMILESã‹ã‚‰è‡ªå‹•ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç‰¹å®š)
protein_seq = "MKTIIALSYIFCLVFA..." # å®Ÿéš›ã®é…åˆ—
taca_linker = "CC(=O)N[C@@H]1[C@@H](O)O[C@H](CO)[C@H](O)[C@@H]1OC[C@H](NC=O)C(=O)NCCCC" 
smarts_end = "C(=O)N" # ãƒªãƒ³ã‚«ãƒ¼ã®æœ«ç«¯ï¼ˆã‚¿ãƒ³ãƒ‘ã‚¯è³ªã¨ã®çµåˆç‚¹ï¼‰ã‚’æŒ‡å®š

wf.prepare_af3_input(
    protein_seq=protein_seq,
    taca_linker_smiles=taca_linker,
    bond_res_idx=105, # Lys105ã«çµåˆ
    terminal_smarts=smarts_end
)

# --- ã“ã“ã§AlphaFold Serverãªã©ã§è¨ˆç®—ã‚’å®Ÿè¡Œ ---

# 3. è¨ˆç®—çµæœã®ä¸€æ‹¬è§£æã¨ãƒ©ãƒ³ã‚­ãƒ³ã‚° (çµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å‰æ)
# df = wf.batch_analyze_models(num_models=5)

# 4. æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®å¯è¦–åŒ–
# if df is not None:
#     best_idx = df.iloc[0]['Model_Index']
#     wf.visualize_model(best_idx)